---
title: "R Notebook"
output: html_notebook
---

#Reference code tutorial:
#uc-r.github.io/svm
#very similar to the lab example in ISLR


```{r}
library(tidyverse)

# read metadata.csv with only "Sample_ID" and "*_sr" features
metadata <- read_csv("./metadata.csv") %>% 
  select(Sample_ID,(matches("_sr$")))

# read antibiotic resistance associated unitigs
unitigs_azm <- read_table2("azm_sr_gwas_filtered_unitigs.Rtab")
unitigs_cfx <- read_table2("cfx_sr_gwas_filtered_unitigs.Rtab")
unitigs_cip <- read_table2("cip_sr_gwas_filtered_unitigs.Rtab")

#Function to transpose unitigs table, join metadata, then create .csv file
unitigs <- function(unitig){
  
  # deparse + substitute combo to extract object name
  unitig_name <- deparse(substitute(unitig))
  
  '%>%' <- tidyr::'%>%'
  
  unitig %>%
    # transpose
    tidyr::pivot_longer(-pattern_id, "Sample_ID", "value") %>% 
    tidyr::pivot_wider(Sample_ID, pattern_id) %>%
    # join relevant antibiotic metadata
    dplyr::inner_join(dplyr::select(metadata, "Sample_ID", dplyr::matches(stringr::str_extract(unitig_name, "[[:alpha:]]+$"))), by = "Sample_ID") %>% 
    dplyr::select(dplyr::last_col(), dplyr::everything(), -"Sample_ID") %>% 
    # rename unitigs to format "geneX" where X is a positive integer
    data.table::setnames(., old = names(.[2:length(.)]), new = paste0('gene', seq_along(.[2:length(.)])), skip_absent = T) %>% 
    tidyr::drop_na() %>% 
    # create .csv file
    readr::write_csv(path=paste0('./', stringr::str_extract(unitig_name,"[[:alpha:]]+[_][[:alpha:]]+"), '.csv'))
}

# Manual Transpose, join, and create .csv files of azm unitigs
# unitigs_azm %>%
#   pivot_longer(-pattern_id, "Sample_ID", "value") %>%
#   pivot_wider(Sample_ID, pattern_id) %>%
#   inner_join(select(metadata, "Sample_ID", matches('^azm')), by = "Sample_ID") %>%
#   select('Sample_ID', last_col(), everything()) %>%
#   data.table::setnames(., old = names(.[2:length(.)]), new = paste0('gene', seq_along(.[2:length(.)])), skip_absent = T) %>% 
#   drop_na() %>%
#   write_csv(path="./unitigs_azm.csv")

# Use 'unitigs' function to create .csv files
unitigs(unitigs_azm)
unitigs(unitigs_cfx)
unitigs(unitigs_cip)
```



#Split into training and testing:
```{r}
createDS <- function(csvname, percent=0.7, seed=05101929){
  stopifnot(is.character(csvname))
  
  '%>%' <- tidyr::'%>%'
  
#Import dataset
svmData <- readr::read_csv(csvname, col_types = readr::cols(.default = readr::col_factor(NULL))) %>% 
  dplyr::select_if(sapply(., nlevels) > 1)
#Split
set.seed(seed)
index <- dplyr::select(svmData,dplyr::matches(stringr::str_extract(unlist(stringr::str_split(csvname, "_"))[2],"^[[:alpha:]]+"))) %>% 
  unlist() %>% 
  caret::createDataPartition(times = 1, p = percent, list = FALSE)

dfTrain <- svmData %>% dplyr::slice(index) #training dataset
dfTest <- svmData %>% dplyr::slice(-index) #testing dataset

#return datasets
dataSets <- list(training = dfTrain, testing = dfTest)
invisible(dataSets)
}
```

#Create dataframes, view:

```{r}
azmDS <- createDS("./unitigs_azm.csv")
tibble::glimpse(azmDS$training[1:6])
```



#Load in SVM-specific packages:

```{r, results='hide'}
library(kernlab)
library(e1071)
library(ISLR)
library(RColorBrewer)
library(ROCR)
```

#Test SVM model 1: linear assumption

```{r}
set.seed(05101929)
svmfit1 <- e1071::svm(azm_sr~., data=azmDS$training, kernel="linear", scale=FALSE)
svmfit1
```


#Tune the 'cost' parameter to identify optimal misclassification threshold:
```{r}
set.seed(05101929)
tune.out1 <- e1071::tune(e1071::svm, azm_sr~., data=azmDS$training, kernel = "linear", ranges=list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
(bestmod1 <- tune.out1$best.model)
```

# Caret pckage mimicry of the above
```{r}
library(caret)
set.seed(05101929)
caretFit <- train(azm_sr~., data=azmDS$training, method= 'svmLinear2', trControl = trainControl("cv", number = 10), tuneGrid = expand.grid(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)), scale = FALSE)
caretFit
```


#Low cost identified

#Construct confusion matrix:

```{r}
ypred1 <- predict(bestmod1, azmDS$testing)
ypred2 <- predict(caretFit, azmDS$testing)
(misclass1 <- table(predict = ypred1, truth = azmDS[[2]][[1]]))
(misclass1 <- table(predict = ypred2, truth = azmDS[[2]][[1]]))
```

Now that it is confirmed that `caret` can achieve the same results will implement below wrapper function:
```{r}
trainMethods <- function(training, outcome, method,
                         seed=05101929, workers = 0, number=10, ...){
  stopifnot(is.character(method), is.object(training), is.character(outcome))
trCtrl <- caret::trainControl("cv", number = number, #cross-validation
                       allowParallel = TRUE) #parallelization

cl <- parallel::makePSOCKcluster(ifelse(workers, workers, parallel::detectCores())) #set number of cores
doParallel::registerDoParallel(cl)
set.seed(seed)

#training and fitting model
  modelRF <- caret::train(as.formula(
    paste0(outcome,"~.")),
    data=training, method=method,
    trControl = trCtrl,
    importance = T,
    ...
  )
parallel::stopCluster(cl)

invisible(modelRF)
}
```

```{r}
#Example of using trainMethods()
azmSVM <- trainMethods(azmDS$training, "azm_sr", method = "svmLinear2", 
                       tuneGrid = expand.grid(cost = seq.int(0.00, 0.1, by = 0.01)),
                       scale = FALSE)
azmSVM
```

#In this model, 
```{r}
azm_predict <- predict(azmSVM, azmDS$testing)
table(pred=azm_predict,true=azmDS$testing$azm_sr)
azm.mean <- mean(azm_predict==azmDS$testing$azm_sr)
```

#... `r azm.mean` of observations were identified correctly.

# Saving Model
```{r}
saveRDS(azmSVM, file = "azmSVM_model")
```

# Ciprofloxacin Model

## Create dataframes, view:

```{r}
cipDS <- createDS("./unitigs_cip.csv")
tibble::glimpse(cipDS$training[1:6])
```

## Build
```{r}
cipSVM <- trainMethods(cipDS$training, "cip_sr", method = "svmLinear2", 
                       tuneGrid = expand.grid(cost = seq.int(0.00, 0.1, by = 0.01)),
                       scale = FALSE)
cipSVM
```

## Prediction, Confusion Matrix, and Accuracy Assessment
```{r}
cip_predict <- predict(cipSVM, cipDS$testing)
table(pred=cip_predict,true=cipDS$testing$cip_sr)
cip.mean <- mean(cip_predict==cipDS$testing$cip_sr)
```

## Saving Model
```{r}
saveRDS(cipSVM, file = "cipSVM_model")
```

# Cefoxatin Model

## Create dataframes, view:

```{r}
cfxDS <- createDS("./unitigs_cfx.csv")
tibble::glimpse(cfxDS$training[1:6])
```

## Build
```{r}
cfxSVM <- trainMethods(cfxDS$training, "cfx_sr", method = "svmLinear2", 
                       tuneGrid = expand.grid(cost = seq.int(0.00, 0.1, by = 0.01)),
                       scale = FALSE)
cfxSVM
```

## Prediction, Confusion Matrix, and Accuracy Assessment
```{r}
cfx_predict <- predict(cfxSVM, cfxDS$testing)
table(pred=cfx_predict,true=cfxDS$testing$cfx_sr)
cfx.mean <- mean(cfx_predict==cfxDS$testing$cfx_sr)
```

## Saving Model
```{r}
saveRDS(cfxSVM, file = "cfxSVM_model")
```

#Moving on to the testing set:

```{r, eval= FALSE}
set.seed(05101929)
svmfit2 <- svm(azm_sr~., data=azmDS$testing, kernel="linear", scale=FALSE)
svmfit2
```

#Verify cost function:
```{r, eval= FALSE}
set.seed(05101929)
tune.out2 <- tune(svm, azm_sr~., data=azmDS$testing, kernel = "linear", ranges=list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
(bestmod2 <- tune.out2$best.model)
```

#Same cost parameter.

```{r, eval= FALSE}
ypred2 <- predict(bestmod2, azmDS$testing)
(misclass2 <- table(predict = ypred2, truth = azmDS[[2]][[1]]))
```


#And in the testing set,
```{r, eval= FALSE}
(127+895)/(127+895+14+7)*100
```

#... 98% of observations were identified correctly.


####.
####Next model set:
####CIP
####.



```{r}
cipDS <- createDS("./unitigs_cip.csv")
tibble::glimpse(cipDS$training[1:6])
```


#Model 1: Linear assumption

```{r}
cipSVM <- trainMethods(cipDS$training, "cip_sr", method = "svmLinear2", 
                       tuneGrid = expand.grid(cost = seq.int(0.00, 0.1, by = 0.01)),
                       scale = FALSE)
cipSVM
```

#Confusion matrix:
```{r}
ypred3 <- predict(cipSVM, cipDS$testing)
(misclass3 <- table(predict = ypred3, truth = cipDS[[2]][[1]]))
```


#So the model accurately predicted:

```{r}
(1157+998)/(1157+998+2+5)*100
```

#... 99.7% of observations.

### CIP Testing Stuff Below:

Note: Removed since training models on testing data and measuring prediction accuracy on testing data isn't informative, unless there is something I am missing. - Arvon

#So, the model accurately predicted:


```{r}
(494+425)/(494+425+4+3)*100
```

#...99.2% of observations.


#What if we cannot assume spread of data can be linearly divided?
#Have to use an alternate 'kernel' (spatial division) method
#For non-linear necesseties, radial kernel is a good default option.

#Model 2: radial assumption




```{r}
cipfit3 <- svm(cip_sr~., data=cipDS$training, kernel="radial", scale=FALSE)
cipfit3
```


```{r}
tune.out5 <- tune(svm, cip_sr~., data=cipDS$training, kernel = "radial", ranges=list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
(bestmod5 <- tune.out5$best.model)
```

## Presumed caret package mimicry
```{r}
cipSVM2 <- trainMethods(cipDS$training, "cip_sr", method = "svmRadialCost", 
                       tuneGrid = expand.grid(C = c(0.001, 0.01, 0.1, 1, 5, 10, 100)),
                       scale = FALSE)
cipSVM2
```


```{r}
summary(bestmod5)
```



```{r}
ypred5 <- predict(bestmod5, cipDS$training)
(misclass5 <- table(predict = ypred5, truth = cipDS[[1]][[1]]))
```


#So, the model accurately predicted:

```{r}
(1146+993)/(1146+993+7+16)*100
```


#... 98.9% of observations



#Evaluating the test set:


```{r}
cipfit4 <- svm(cip_sr~., data=cipDS$testing, kernel="radial", scale=FALSE)
cipfit4
```



#Testing the optimal misclassification penalty:

```{r}
tune.out6 <- tune(svm, cip_sr~., data=cipDS$testing, kernel = "radial", ranges=list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
(bestmod6 <- tune.out6$best.model)
```


#A high misclassification cost was found.

```{r}
summary(bestmod6)
```


```{r}
ypred6 <- predict(bestmod6, cipDS$testing)
(misclass6 <- table(predict = ypred6, truth = cipDS[[2]][[1]]))
```

#So, the model accurately predicted:

```{r}
(497+427)/(497+427+1+1)*100
```


#...99.8% of observations.
