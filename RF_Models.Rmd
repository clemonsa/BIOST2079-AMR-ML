---
title: "Random Forest AMR Prediction"
author: "Arvon Clemons"
date: "9/14/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Libraries
```{r warning = FALSE, message=FALSE, echo=FALSE}
#install packages only if you have not already done so 
list.of.packages <- c("randomForest", "ggplot2", "dplyr", "caret",
                      "readr", "e1071", "mlbench", "slam","parallel", "doParallel")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
#library packages
for (pkg in c("randomForest", "ggplot2", "dplyr",
              "caret", "readr","parallel", "doParallel")) {
  library(pkg, character.only = TRUE)
  }
```

# Function to create Training and Test datasets
```{r}
createDS <- function(csvname, percent=0.7, seed=05101929){
  stopifnot(is.character(csvname))
  
  '%>%' <- tidyr::'%>%'
  
#Import dataset
rfData <- readr::read_csv(csvname, col_types = readr::cols(.default = readr::col_factor(NULL))) %>% 
  dplyr::select_if(sapply(., nlevels) > 1)
#Split
set.seed(seed)
index <- dplyr::select(rfData,dplyr::matches(stringr::str_extract(unlist(stringr::str_split(csvname, "_"))[2],"^[[:alpha:]]+"))) %>% 
  unlist() %>% 
  caret::createDataPartition(times = 1, p = percent, list = FALSE)

dfTrain <- rfData %>% dplyr::slice(index) #training dataset
dfTest <- rfData %>% dplyr::slice(-index) #testing dataset

#return datasets
dataSets <- list(training = dfTrain, testing = dfTest)
invisible(dataSets)
}

#Example of using createDS()
azmDS <- createDS("./unitigs_azm.csv")
tibble::glimpse(azmDS$training[1:6])
# Rows: 2,435
# Columns: 6
# $ azm_sr <fct> 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
# $ gene1  <fct> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
# $ gene2  <fct> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
# $ gene3  <fct> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
# $ gene4  <fct> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
# $ gene5  <fct> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
```

# Function to Train and Fit Random Forest Model (USE CAUTION)!!!
```{r}
trainMethods <- function(training, outcome, method, tunelength=3,seed=05101929, workers = 0, number=10){
  stopifnot(is.character(method), is.object(training), is.character(outcome))
trCtrl <- caret::trainControl("cv", number = number, #cross-validation
                       allowParallel = TRUE) #parallelization

cl <- parallel::makePSOCKcluster(ifelse(workers, workers, parallel::detectCores())) #set number of cores
doParallel::registerDoParallel(cl)
set.seed(seed)

#training and fitting model
  modelRF <- caret::train(as.formula(
    paste0(outcome,"~.")),
    data=training, method=method,
    tuneLength = tunelength,
    trControl = trCtrl,
    importance = T
  )
parallel::stopCluster()

invisible(modelRF)
}

#Example of using trainMethods()
azmRF <- trainMethods(azmDS$training, "azm_sr", method = "parRF")
azmRF
# Parallel Random Forest 
# 
# 2435 samples
#  490 predictor
#    2 classes: '1', '0' 
# 
# No pre-processing
# Resampling: Cross-Validated (10 fold) 
# Summary of sample sizes: 2191, 2192, 2191, 2192, 2192, 2192, ... 
# Resampling results across tuning parameters:
# 
#   mtry  Accuracy   Kappa     
#     2   0.8726911  0.01630407
#   246   0.9733084  0.88249905
#   490   0.9700179  0.86726412
# 
# Accuracy was used to select the optimal model using the largest value.
# The final value used for the model was mtry = 246.
```

# Import and Split Data
```{r}
#Import
## May require using "data_clean_script.R" to create "unitigs_cip.csv" in local directory
cipData <- read_csv("./unitigs_cip.csv", col_types = cols(.default = col_factor(NULL))) %>% 
  select_if(sapply(., nlevels) > 1)
#Split
set.seed(05101929)
index <- cipData$cip_sr %>% 
  createDataPartition(times = 1, p = 0.7, list = FALSE)

cipTrain <- cipData %>% slice(index)
cipTest <- cipData %>% slice(-index)
```

# Practice Model Training and Fit
```{r}
miniData <- cipData[1:1200, ] #subset to first 1200 observations
index2 <- miniData$cip_sr %>% 
  createDataPartition(times = 1, p = 0.8, list = FALSE)

miniTrain <- miniData %>% slice(index2) #train subset
miniTest <- miniData %>% slice(-index2) #test subset

trCtrl <- trainControl("cv", number = 10, #cross-validation
                       allowParallel = TRUE) #parallelization

# cl <- makePSOCKcluster(6) #set number of cores
# registerDoParallel(cl)
# set.seed(05101929)
# 
# system.time(
#   pracRF <- train(
#     cip_sr~., data=miniTrain, method="parRF",
#     trControl = trCtrl,
#     importance = T
#   )
# )
# stopCluster(cl)


saveRDS(pracRF, file = "mockRF_model") #save mock model
predictedAR <- pracRF %>% predict(miniTest) #mock predictions
mean(predictedAR == miniTest$cip_sr) #assess mock model accuracy
#[1] 0.9958159

predictedAR2 <- pracRF %>% predict(cipTest) #mock predictions on full dataset
mean(predictedAR == cipTest$cip_sr) #assess mock model accuracy on full dataset
#[1] 0.9773218
```

# Full Model Training and Fit (DO NOT RUN!!!!)
```{r}
trCtrl <- caret::trainControl("cv", number = 10, #cross-validation
                       allowParallel = TRUE) #parallelization

tunegrid <- expand.grid(.mtry=c(1:15)) #gridsearch for mtry parameter

# Select Cores for Parallelization
cl <- parallel::makePSOCKcluster(4) #set number of cores
doParallel::registerDoParallel(cl)
set.seed(05101929)

#Model Fit
modelRF <- caret::train(
  azm_sr~., data = azm$training, method = "parRF",
  tuneGrid = tunegrid,
  trControl = trCtrl,
  importance = TRUE
  )
#After fitting model

saveRDS(modelRF, file = "azmRF_model2") #save full model
predictedAR <- modelRF %>% predict(azm$testing) #full predictions
parallel::stopCluster(cl)
mean(predictedAR == azm$testing$azm_sr) #assess full model accuracy

# Best tuning parameter
modelRF$bestTune
```
