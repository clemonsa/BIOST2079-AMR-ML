---
title: "Random Forest AMR Prediction"
author: "Arvon Clemons"
date: "9/14/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Libraries
```{r echo=FALSE}
library(tidyverse)
library(caret)
```


# Data Cleaning
```{r, eval=FALSE}
# read metadata.csv with only "Sample_ID" and "*_sr" features
metadata <- read_csv("./metadata.csv") %>% 
  select(Sample_ID,(matches("_sr$")))

# read antibiotic resistance associated unitigs
unitigs_azm <- read_table2("azm_sr_gwas_filtered_unitigs.Rtab")
unitigs_cfx <- read_table2("cfx_sr_gwas_filtered_unitigs.Rtab")
unitigs_cip <- read_table2("cip_sr_gwas_filtered_unitigs.Rtab")

#Function to transpose unitigs table, join metadata, then create .csv file
unitigs <- function(unitig){
  
  # deparse + substitute combo to extract object name
  unitig_name <- deparse(substitute(unitig))
  
  '%>%' <- tidyr::'%>%'
  
  unitig %>%
    # transpose
    tidyr::pivot_longer(-pattern_id, "Sample_ID", "value") %>% 
    tidyr::pivot_wider(Sample_ID, pattern_id) %>%
    # join relevant antibiotic metadata
    dplyr::inner_join(dplyr::select(metadata, "Sample_ID", dplyr::matches(stringr::str_extract(unitig_name, "[[:alpha:]]+$"))), by = "Sample_ID") %>% 
    dplyr::select(dplyr::last_col(), dplyr::everything(), -"Sample_ID") %>% 
    # rename unitigs to format "geneX" where X is a positive integer
    data.table::setnames(., old = names(.[2:length(.)]), new = paste0('gene', seq_along(.[2:length(.)])), skip_absent = T) %>% 
    # relabel into "neg" and "pos"
    mutate(across(where(is.numeric), ~if_else(. == 0, "neg", "pos"))) %>% 
    tidyr::drop_na() %>% 
    # create .csv file
    readr::write_csv(path=paste0('./', stringr::str_extract(unitig_name,"[[:alpha:]]+[_][[:alpha:]]+"), '.csv'))
}

# Manual Transpose, join, and create .csv files of azm unitigs
# unitigs_azm %>%
#   pivot_longer(-pattern_id, "Sample_ID", "value") %>%
#   pivot_wider(Sample_ID, pattern_id) %>%
#   inner_join(select(metadata, "Sample_ID", matches('^azm')), by = "Sample_ID") %>%
#   select('Sample_ID', last_col(), everything()) %>%
#   data.table::setnames(., old = names(.[2:length(.)]), new = paste0('gene', seq_along(.[2:length(.)])), skip_absent = T) %>% 
#   drop_na() %>%
#   write_csv(path="./unitigs_azm.csv")

# Use 'unitigs' function to create .csv files
unitigs(unitigs_azm)
unitigs(unitigs_cfx)
unitigs(unitigs_cip)
```


# Function to create Training and Test datasets
```{r, eval=FALSE}
createDS <- function(csvname, percent=0.7, seed=05101929){
  stopifnot(is.character(csvname))
  
  '%>%' <- tidyr::'%>%'
  
#Import dataset
rfData <- readr::read_csv(csvname, col_types = readr::cols(.default = readr::col_factor(NULL))) %>% 
  dplyr::select_if(sapply(., nlevels) > 1)
#Split
set.seed(seed)
index <- dplyr::select(rfData,dplyr::matches(stringr::str_extract(unlist(stringr::str_split(csvname, "_"))[2],"^[[:alpha:]]+"))) %>% 
  unlist() %>% 
  caret::createDataPartition(times = 1, p = percent, list = FALSE)

dfTrain <- rfData %>% dplyr::slice(index) #training dataset
dfTest <- rfData %>% dplyr::slice(-index) #testing dataset

#return datasets
dataSets <- list(training = dfTrain, testing = dfTest)
invisible(dataSets)
}

#Example of using createDS()
azmDS <- createDS("./unitigs_azm.csv")
tibble::glimpse(azmDS$training[1:6])
# Observations: 2,435
# Variables: 6
# $ azm_sr <fct> pos, pos, pos, neg, pos, neg, neg, pos, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, n…
# $ gene1  <fct> neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, n…
# $ gene2  <fct> neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, n…
# $ gene3  <fct> neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, n…
# $ gene4  <fct> neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, n…
# $ gene5  <fct> neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, neg, n…
```

# Function to Train and Fit Random Forest Model (USE CAUTION)!!!
```{r, eval=FALSE}
trainMethods <- function(training, outcome,
                         seed=05101929, workers = 0, ...){
  stopifnot(is.object(training), is.character(outcome))
trCtrl <- caret::trainControl(method = "cv", number = 10, #cross-validation
                       allowParallel = TRUE, #parallelization
                       summaryFunction = twoClassSummary,
                       classProbs = TRUE) #class probabilities

cl <- parallel::makePSOCKcluster(ifelse(workers, workers, parallel::detectCores())) #set number of cores
doParallel::registerDoParallel(cl)
set.seed(seed)

#training and fitting model
  modelRF <- caret::train(as.formula(
    paste0(outcome,"~.")),
    data=training,
    trControl = trCtrl,
    metric = "ROC",
    importance = T,
    ...
  )
parallel::stopCluster(cl)

invisible(modelRF)
}

#Example of using trainMethods()
azmRF <- trainMethods(azmDS$training, "azm_sr", method = "parRF", workers = 8, tuneLength = 15)
azmRF
# Parallel Random Forest 
# 
# 2435 samples
#  490 predictor
#    2 classes: 'pos', 'neg' 
# 
# No pre-processing
# Resampling: Cross-Validated (10 fold) 
# Summary of sample sizes: 2191, 2192, 2191, 2192, 2192, 2192, ... 
# Resampling results across tuning parameters:
# 
#   mtry  ROC        Sens         Spec     
#     2   0.9689613  0.009576613  1.0000000
#    36   0.9820421  0.847177419  0.9863318
#    71   0.9822760  0.901411290  0.9839733
#   106   0.9797329  0.908064516  0.9835016
#   141   0.9816982  0.917540323  0.9835016
#   176   0.9821858  0.914314516  0.9835016
#   211   0.9791046  0.907862903  0.9830299
#   245   0.9797244  0.911088710  0.9830299
#   280   0.9792163  0.901411290  0.9825582
#   315   0.9770951  0.901411290  0.9825582
#   350   0.9715289  0.901411290  0.9835016
#   385   0.9732403  0.894959677  0.9825582
#   420   0.9714728  0.898185484  0.9825582
#   455   0.9747380  0.888508065  0.9825582
#   490   0.9724808  0.888508065  0.9816148
# 
# ROC was used to select the optimal model using the largest value.
# The final value used for the model was mtry = 71.
```
# Model Tuning on `mtry`
```{r}
mBest <- azmRF$bestTune[[1]]
tBest <- -1
while(tBest != mBest){
  mGrid <- var_seq(p = mBest, classification = TRUE, len = 15) %>% expand_grid(mtry = ., s = 0)
  
  azmRF <- trainMethods(azmDS$training, "azm_sr", method = "parRF", workers = 8, tuneGrid = mGrid)
  tBest <- azmRF$bestTune[[1]]
}
```

# Assess model accuracy
```{r}
predictedAR <- predict(azmRF, azmDS$testing) #full predictions
mean(predictedAR == azmDS$testing$azm_sr) #assess full model accuracy
confusionMatrix(predictedAR, azmDS$testing$azm_sr) #confusion matrix
```

# Plots
```{r}
plot.train(azmRF) #graphs Tuning Accuracy
varImp(azmRF) %>% dotPlot() #graphs Importance
```

# Save Model
```{r}
saveRDS(azmRF, file = "azmRF_model") #save model
```